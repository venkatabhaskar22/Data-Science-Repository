{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Digits - Classification Using SVM\n",
    "\n",
    "In this Programme explore the popular MNIST dataset and build an SVM model to classify handwritten digits. Here is a detailed description of the dataset.\n",
    "\n",
    "We'll divide the analysis into the following parts:\n",
    "- Data understanding and cleaning\n",
    "- Data preparation for model building\n",
    "- Building an SVM model - hyperparameter tuning, model evaluation etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding and Cleaning\n",
    " \n",
    " Let's understand the dataset and see if it needs some cleaning etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "digits = pd.read_csv(\"../input/trains-dataset/trains.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>pixel11</th>\n",
       "      <th>pixel12</th>\n",
       "      <th>pixel13</th>\n",
       "      <th>pixel14</th>\n",
       "      <th>pixel15</th>\n",
       "      <th>pixel16</th>\n",
       "      <th>pixel17</th>\n",
       "      <th>pixel18</th>\n",
       "      <th>pixel19</th>\n",
       "      <th>pixel20</th>\n",
       "      <th>pixel21</th>\n",
       "      <th>pixel22</th>\n",
       "      <th>pixel23</th>\n",
       "      <th>pixel24</th>\n",
       "      <th>pixel25</th>\n",
       "      <th>pixel26</th>\n",
       "      <th>pixel27</th>\n",
       "      <th>pixel28</th>\n",
       "      <th>pixel29</th>\n",
       "      <th>pixel30</th>\n",
       "      <th>pixel31</th>\n",
       "      <th>pixel32</th>\n",
       "      <th>pixel33</th>\n",
       "      <th>pixel34</th>\n",
       "      <th>pixel35</th>\n",
       "      <th>pixel36</th>\n",
       "      <th>pixel37</th>\n",
       "      <th>pixel38</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel744</th>\n",
       "      <th>pixel745</th>\n",
       "      <th>pixel746</th>\n",
       "      <th>pixel747</th>\n",
       "      <th>pixel748</th>\n",
       "      <th>pixel749</th>\n",
       "      <th>pixel750</th>\n",
       "      <th>pixel751</th>\n",
       "      <th>pixel752</th>\n",
       "      <th>pixel753</th>\n",
       "      <th>pixel754</th>\n",
       "      <th>pixel755</th>\n",
       "      <th>pixel756</th>\n",
       "      <th>pixel757</th>\n",
       "      <th>pixel758</th>\n",
       "      <th>pixel759</th>\n",
       "      <th>pixel760</th>\n",
       "      <th>pixel761</th>\n",
       "      <th>pixel762</th>\n",
       "      <th>pixel763</th>\n",
       "      <th>pixel764</th>\n",
       "      <th>pixel765</th>\n",
       "      <th>pixel766</th>\n",
       "      <th>pixel767</th>\n",
       "      <th>pixel768</th>\n",
       "      <th>pixel769</th>\n",
       "      <th>pixel770</th>\n",
       "      <th>pixel771</th>\n",
       "      <th>pixel772</th>\n",
       "      <th>pixel773</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1    ...     pixel781  pixel782  pixel783\n",
       "0      1       0       0    ...            0         0         0\n",
       "1      0       0       0    ...            0         0         0\n",
       "2      1       0       0    ...            0         0         0\n",
       "3      4       0       0    ...            0         0         0\n",
       "4      0       0       0    ...            0         0         0\n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# head\n",
    "digits.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "four = digits.iloc[3, 1:]\n",
    "four.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f7bf893d550>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "four = four.values.reshape(28, 28)\n",
    "plt.imshow(four, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Side note: Indexing Recall ####\n",
    "`list =    [0, 4, 2, 10, 22, 101, 10]` <br>\n",
    "`indices = [0, 1, 2, 3, ...,        ]` <br>\n",
    "`reverse = [-n           -3  -2   -1]` <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0 220 179   6   0   0   0   0   0   0   0   0   9  77   0   0   0   0]\n",
      " [  0  28 247  17   0   0   0   0   0   0   0   0  27 202   0   0   0   0]\n",
      " [  0   0 242 155   0   0   0   0   0   0   0   0  27 254  63   0   0   0]\n",
      " [  0   0 160 207   6   0   0   0   0   0   0   0  27 254  65   0   0   0]\n",
      " [  0   0 127 254  21   0   0   0   0   0   0   0  20 239  65   0   0   0]\n",
      " [  0   0  77 254  21   0   0   0   0   0   0   0   0 195  65   0   0   0]\n",
      " [  0   0  70 254  21   0   0   0   0   0   0   0   0 195 142   0   0   0]\n",
      " [  0   0  56 251  21   0   0   0   0   0   0   0   0 195 227   0   0   0]\n",
      " [  0   0   0 222 153   5   0   0   0   0   0   0   0 120 240  13   0   0]\n",
      " [  0   0   0  67 251  40   0   0   0   0   0   0   0  94 255  69   0   0]\n",
      " [  0   0   0   0 234 184   0   0   0   0   0   0   0  19 245  69   0   0]\n",
      " [  0   0   0   0 234 169   0   0   0   0   0   0   0   3 199 182  10   0]\n",
      " [  0   0   0   0 154 205   4   0   0  26  72 128 203 208 254 254 131   0]\n",
      " [  0   0   0   0  61 254 129 113 186 245 251 189  75  56 136 254  73   0]\n",
      " [  0   0   0   0  15 216 233 233 159 104  52   0   0   0  38 254  73   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  18 254  73   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  18 254  73   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   5 206 106   0]]\n"
     ]
    }
   ],
   "source": [
    "# visualise the array\n",
    "print(four[5:-5, 5:-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4684\n",
       "7    4401\n",
       "3    4351\n",
       "9    4188\n",
       "2    4177\n",
       "6    4137\n",
       "0    4132\n",
       "4    4072\n",
       "8    4063\n",
       "5    3795\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summarise the counts of 'label' to see how many labels of each digit are present\n",
    "digits.label.astype('category').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    11.15\n",
       "7    10.48\n",
       "3    10.36\n",
       "9     9.97\n",
       "2     9.95\n",
       "6     9.85\n",
       "0     9.84\n",
       "4     9.70\n",
       "8     9.67\n",
       "5     9.04\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summarise count in terms of percentage \n",
    "100*(round(digits.label.astype('category').value_counts()/len(digits.index), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, each digit/label has an approximately 9%-11% fraction in the dataset and the **dataset is balanced**. This is an important factor in considering the choices of models to be used, especially SVM, since **SVMs rarely perform well on imbalanced data** (think about why that might be the case).\n",
    "\n",
    "Let's quickly look at missing values, if any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label       0\n",
       "pixel0      0\n",
       "pixel1      0\n",
       "pixel2      0\n",
       "pixel3      0\n",
       "pixel4      0\n",
       "pixel5      0\n",
       "pixel6      0\n",
       "pixel7      0\n",
       "pixel8      0\n",
       "pixel9      0\n",
       "pixel10     0\n",
       "pixel11     0\n",
       "pixel12     0\n",
       "pixel13     0\n",
       "pixel14     0\n",
       "pixel15     0\n",
       "pixel16     0\n",
       "pixel17     0\n",
       "pixel18     0\n",
       "pixel19     0\n",
       "pixel20     0\n",
       "pixel21     0\n",
       "pixel22     0\n",
       "pixel23     0\n",
       "pixel24     0\n",
       "pixel25     0\n",
       "pixel26     0\n",
       "pixel27     0\n",
       "pixel28     0\n",
       "           ..\n",
       "pixel754    0\n",
       "pixel755    0\n",
       "pixel756    0\n",
       "pixel757    0\n",
       "pixel758    0\n",
       "pixel759    0\n",
       "pixel760    0\n",
       "pixel761    0\n",
       "pixel762    0\n",
       "pixel763    0\n",
       "pixel764    0\n",
       "pixel765    0\n",
       "pixel766    0\n",
       "pixel767    0\n",
       "pixel768    0\n",
       "pixel769    0\n",
       "pixel770    0\n",
       "pixel771    0\n",
       "pixel772    0\n",
       "pixel773    0\n",
       "pixel774    0\n",
       "pixel775    0\n",
       "pixel776    0\n",
       "pixel777    0\n",
       "pixel778    0\n",
       "pixel779    0\n",
       "pixel780    0\n",
       "pixel781    0\n",
       "pixel782    0\n",
       "pixel783    0\n",
       "Length: 785, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# missing values - there are none\n",
    "digits.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, let's look at the average values of each column, since we'll need to do some rescaling in case the ranges vary too much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>pixel11</th>\n",
       "      <th>pixel12</th>\n",
       "      <th>pixel13</th>\n",
       "      <th>pixel14</th>\n",
       "      <th>pixel15</th>\n",
       "      <th>pixel16</th>\n",
       "      <th>pixel17</th>\n",
       "      <th>pixel18</th>\n",
       "      <th>pixel19</th>\n",
       "      <th>pixel20</th>\n",
       "      <th>pixel21</th>\n",
       "      <th>pixel22</th>\n",
       "      <th>pixel23</th>\n",
       "      <th>pixel24</th>\n",
       "      <th>pixel25</th>\n",
       "      <th>pixel26</th>\n",
       "      <th>pixel27</th>\n",
       "      <th>pixel28</th>\n",
       "      <th>pixel29</th>\n",
       "      <th>pixel30</th>\n",
       "      <th>pixel31</th>\n",
       "      <th>pixel32</th>\n",
       "      <th>pixel33</th>\n",
       "      <th>pixel34</th>\n",
       "      <th>pixel35</th>\n",
       "      <th>pixel36</th>\n",
       "      <th>pixel37</th>\n",
       "      <th>pixel38</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel744</th>\n",
       "      <th>pixel745</th>\n",
       "      <th>pixel746</th>\n",
       "      <th>pixel747</th>\n",
       "      <th>pixel748</th>\n",
       "      <th>pixel749</th>\n",
       "      <th>pixel750</th>\n",
       "      <th>pixel751</th>\n",
       "      <th>pixel752</th>\n",
       "      <th>pixel753</th>\n",
       "      <th>pixel754</th>\n",
       "      <th>pixel755</th>\n",
       "      <th>pixel756</th>\n",
       "      <th>pixel757</th>\n",
       "      <th>pixel758</th>\n",
       "      <th>pixel759</th>\n",
       "      <th>pixel760</th>\n",
       "      <th>pixel761</th>\n",
       "      <th>pixel762</th>\n",
       "      <th>pixel763</th>\n",
       "      <th>pixel764</th>\n",
       "      <th>pixel765</th>\n",
       "      <th>pixel766</th>\n",
       "      <th>pixel767</th>\n",
       "      <th>pixel768</th>\n",
       "      <th>pixel769</th>\n",
       "      <th>pixel770</th>\n",
       "      <th>pixel771</th>\n",
       "      <th>pixel772</th>\n",
       "      <th>pixel773</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.00000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.00000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.00000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.456643</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00300</td>\n",
       "      <td>0.011190</td>\n",
       "      <td>0.005143</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>0.001310</td>\n",
       "      <td>0.010548</td>\n",
       "      <td>0.027262</td>\n",
       "      <td>0.050905</td>\n",
       "      <td>0.066405</td>\n",
       "      <td>0.129571</td>\n",
       "      <td>...</td>\n",
       "      <td>3.772524</td>\n",
       "      <td>2.748905</td>\n",
       "      <td>1.796452</td>\n",
       "      <td>1.089905</td>\n",
       "      <td>0.563190</td>\n",
       "      <td>0.239571</td>\n",
       "      <td>0.093524</td>\n",
       "      <td>0.024833</td>\n",
       "      <td>0.000857</td>\n",
       "      <td>0.001405</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006143</td>\n",
       "      <td>0.035833</td>\n",
       "      <td>0.082357</td>\n",
       "      <td>0.114905</td>\n",
       "      <td>0.178714</td>\n",
       "      <td>0.301452</td>\n",
       "      <td>0.413643</td>\n",
       "      <td>0.513667</td>\n",
       "      <td>0.558833</td>\n",
       "      <td>0.677857</td>\n",
       "      <td>0.60281</td>\n",
       "      <td>0.489238</td>\n",
       "      <td>0.340214</td>\n",
       "      <td>0.219286</td>\n",
       "      <td>0.117095</td>\n",
       "      <td>0.059024</td>\n",
       "      <td>0.02019</td>\n",
       "      <td>0.017238</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.887730</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.56812</td>\n",
       "      <td>1.626927</td>\n",
       "      <td>1.053972</td>\n",
       "      <td>0.043916</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.078072</td>\n",
       "      <td>0.232634</td>\n",
       "      <td>1.131661</td>\n",
       "      <td>2.310396</td>\n",
       "      <td>3.121847</td>\n",
       "      <td>3.259128</td>\n",
       "      <td>4.992894</td>\n",
       "      <td>...</td>\n",
       "      <td>26.957829</td>\n",
       "      <td>22.879248</td>\n",
       "      <td>18.595109</td>\n",
       "      <td>14.434439</td>\n",
       "      <td>10.517823</td>\n",
       "      <td>6.469315</td>\n",
       "      <td>3.976306</td>\n",
       "      <td>1.846016</td>\n",
       "      <td>0.139556</td>\n",
       "      <td>0.287891</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.949803</td>\n",
       "      <td>2.350859</td>\n",
       "      <td>3.934280</td>\n",
       "      <td>4.543583</td>\n",
       "      <td>5.856772</td>\n",
       "      <td>7.219742</td>\n",
       "      <td>8.928286</td>\n",
       "      <td>10.004069</td>\n",
       "      <td>10.129595</td>\n",
       "      <td>11.254931</td>\n",
       "      <td>10.69603</td>\n",
       "      <td>9.480066</td>\n",
       "      <td>7.950251</td>\n",
       "      <td>6.312890</td>\n",
       "      <td>4.633819</td>\n",
       "      <td>3.274488</td>\n",
       "      <td>1.75987</td>\n",
       "      <td>1.894498</td>\n",
       "      <td>0.414264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>116.00000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>216.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>157.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>243.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>231.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.00000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>253.00000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              label   pixel0   pixel1    ...     pixel781  pixel782  pixel783\n",
       "count  42000.000000  42000.0  42000.0    ...      42000.0   42000.0   42000.0\n",
       "mean       4.456643      0.0      0.0    ...          0.0       0.0       0.0\n",
       "std        2.887730      0.0      0.0    ...          0.0       0.0       0.0\n",
       "min        0.000000      0.0      0.0    ...          0.0       0.0       0.0\n",
       "25%        2.000000      0.0      0.0    ...          0.0       0.0       0.0\n",
       "50%        4.000000      0.0      0.0    ...          0.0       0.0       0.0\n",
       "75%        7.000000      0.0      0.0    ...          0.0       0.0       0.0\n",
       "max        9.000000      0.0      0.0    ...          0.0       0.0       0.0\n",
       "\n",
       "[8 rows x 785 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average values/distributions of features\n",
    "description = digits.describe()\n",
    "description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the max value of the mean and maximum values of some features (pixels) is 139, 255 etc., whereas most features lie in much lower ranges  (look at description of pixel 0, pixel 1 etc. above).\n",
    "\n",
    "Thus, it seems like a good idea to rescale the features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation for Model Building\n",
    "\n",
    "Let's now prepare the dataset for building the model. We'll only use a fraction of the data else training will take a long time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:8: DataConversionWarning: Data with input dtype int64 were all converted to float64 by the scale function.\n",
      "  \n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4200, 784)\n",
      "(37800, 784)\n",
      "(4200,)\n",
      "(37800,)\n"
     ]
    }
   ],
   "source": [
    "# Creating training and test sets\n",
    "# Splitting the data into train and test\n",
    "X = digits.iloc[:, 1:]\n",
    "Y = digits.iloc[:, 0]\n",
    "\n",
    "# Rescaling the features\n",
    "from sklearn.preprocessing import scale\n",
    "X = scale(X)\n",
    "\n",
    "# train test split with train_size=10% and test size=90%\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, train_size=0.10, random_state=101)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete test set from memory, to avoid a memory error\n",
    "# we'll anyway use CV to evaluate the model, and can use the separate test.csv file as well\n",
    "# to evaluate the model finally\n",
    "\n",
    "# del x_test\n",
    "# del y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building\n",
    "\n",
    "Let's now build the model and tune the hyperparameters. Let's start with a **linear model** first.\n",
    "\n",
    "### Linear SVM\n",
    "\n",
    "Let's first try building a linear SVM model (i.e. a linear kernel). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "\n",
    "# an initial SVM model with linear kernel   \n",
    "svm_linear = svm.SVC(kernel='linear')\n",
    "\n",
    "# fit\n",
    "svm_linear.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 0, 0, 1, 9, 1, 5, 0, 6])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict\n",
    "predictions = svm_linear.predict(x_test)\n",
    "predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3615,    0,   12,    8,    8,   28,   28,    5,    9,    2],\n",
       "       [   0, 4089,   16,   23,    9,    3,    3,   13,   25,    4],\n",
       "       [  54,   48, 3363,   64,   74,   13,   53,   52,   59,   10],\n",
       "       [  20,   28,  121, 3387,    8,  175,    5,   54,   58,   44],\n",
       "       [  12,   12,   26,    2, 3399,    7,   41,   41,    4,  158],\n",
       "       [  49,   42,   32,  177,   41, 2899,   54,   14,   82,   28],\n",
       "       [  36,   16,   55,    5,   34,   37, 3486,    3,   21,    0],\n",
       "       [   9,   27,   37,   22,   70,   10,    4, 3619,   14,  142],\n",
       "       [  26,   86,   71,  137,   24,  137,   29,   26, 3096,   33],\n",
       "       [  38,   11,   39,   26,  182,   19,    1,  207,   27, 3228]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluation: accuracy\n",
    "# C(i, j) represents the number of points known to be in class i \n",
    "# but predicted to be in class j\n",
    "confusion = metrics.confusion_matrix(y_true = y_test, y_pred = predictions)\n",
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9042592592592592"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# measure accuracy\n",
    "metrics.accuracy_score(y_true=y_test, y_pred=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.95      3715\n",
      "           1       0.94      0.98      0.96      4185\n",
      "           2       0.89      0.89      0.89      3790\n",
      "           3       0.88      0.87      0.87      3900\n",
      "           4       0.88      0.92      0.90      3702\n",
      "           5       0.87      0.85      0.86      3418\n",
      "           6       0.94      0.94      0.94      3693\n",
      "           7       0.90      0.92      0.91      3954\n",
      "           8       0.91      0.84      0.88      3665\n",
      "           9       0.88      0.85      0.87      3778\n",
      "\n",
      "   micro avg       0.90      0.90      0.90     37800\n",
      "   macro avg       0.90      0.90      0.90     37800\n",
      "weighted avg       0.90      0.90      0.90     37800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# class-wise accuracy\n",
    "class_wise = metrics.classification_report(y_true=y_test, y_pred=predictions)\n",
    "print(class_wise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run gc.collect() (garbage collect) to free up memory\n",
    "# else, since the dataset is large and SVM is computationally heavy,\n",
    "# it'll throw a memory error while training\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-Linear SVM\n",
    "\n",
    "Let's now try a non-linear model with the RBF kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rbf kernel with other hyperparameters kept to default \n",
    "svm_rbf = svm.SVC(kernel='rbf')\n",
    "svm_rbf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9255820105820106\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "predictions = svm_rbf.predict(x_test)\n",
    "\n",
    "# accuracy \n",
    "print(metrics.accuracy_score(y_true=y_test, y_pred=predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy achieved with a non-linear kernel is slightly higher than a linear one. Let's now do a grid search CV to tune the hyperparameters C and gamma.\n",
    "\n",
    "### Grid Search Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'C': [1, 10, 100], 'gamma': [0.01, 0.001, 0.0001]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# conduct (grid search) cross-validation to find the optimal values \n",
    "# of cost C and the choice of kernel\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'C':[1, 10, 100], \n",
    "             'gamma': [1e-2, 1e-3, 1e-4]}\n",
    "\n",
    "# instantiate a model \n",
    "svc_grid_search = svm.SVC(kernel=\"rbf\")\n",
    "\n",
    "# create a classifier to perform grid search\n",
    "clf = GridSearchCV(svc_grid_search, param_grid=parameters, scoring='accuracy')\n",
    "\n",
    "# fit\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.034261</td>\n",
       "      <td>0.112113</td>\n",
       "      <td>5.335857</td>\n",
       "      <td>0.195410</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 1, 'gamma': 0.01}</td>\n",
       "      <td>0.723450</td>\n",
       "      <td>0.707857</td>\n",
       "      <td>0.712241</td>\n",
       "      <td>0.714524</td>\n",
       "      <td>0.006570</td>\n",
       "      <td>9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.775536</td>\n",
       "      <td>0.065862</td>\n",
       "      <td>3.208063</td>\n",
       "      <td>0.090185</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 1, 'gamma': 0.001}</td>\n",
       "      <td>0.919458</td>\n",
       "      <td>0.905714</td>\n",
       "      <td>0.914102</td>\n",
       "      <td>0.913095</td>\n",
       "      <td>0.005659</td>\n",
       "      <td>4</td>\n",
       "      <td>0.964962</td>\n",
       "      <td>0.967500</td>\n",
       "      <td>0.967892</td>\n",
       "      <td>0.966785</td>\n",
       "      <td>0.001298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.492945</td>\n",
       "      <td>0.085976</td>\n",
       "      <td>4.250450</td>\n",
       "      <td>0.048946</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'C': 1, 'gamma': 0.0001}</td>\n",
       "      <td>0.867427</td>\n",
       "      <td>0.864286</td>\n",
       "      <td>0.872584</td>\n",
       "      <td>0.868095</td>\n",
       "      <td>0.003419</td>\n",
       "      <td>6</td>\n",
       "      <td>0.891312</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.893329</td>\n",
       "      <td>0.891547</td>\n",
       "      <td>0.001369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.427613</td>\n",
       "      <td>0.120915</td>\n",
       "      <td>5.021867</td>\n",
       "      <td>0.129651</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 10, 'gamma': 0.01}</td>\n",
       "      <td>0.742694</td>\n",
       "      <td>0.727143</td>\n",
       "      <td>0.732283</td>\n",
       "      <td>0.734048</td>\n",
       "      <td>0.006473</td>\n",
       "      <td>7</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.040052</td>\n",
       "      <td>0.101342</td>\n",
       "      <td>2.933708</td>\n",
       "      <td>0.074563</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 10, 'gamma': 0.001}</td>\n",
       "      <td>0.937990</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.916249</td>\n",
       "      <td>0.922857</td>\n",
       "      <td>0.010748</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999285</td>\n",
       "      <td>0.999643</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999643</td>\n",
       "      <td>0.000292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.963537</td>\n",
       "      <td>0.085688</td>\n",
       "      <td>2.717321</td>\n",
       "      <td>0.063449</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'C': 10, 'gamma': 0.0001}</td>\n",
       "      <td>0.920171</td>\n",
       "      <td>0.906429</td>\n",
       "      <td>0.913386</td>\n",
       "      <td>0.913333</td>\n",
       "      <td>0.005613</td>\n",
       "      <td>3</td>\n",
       "      <td>0.959957</td>\n",
       "      <td>0.959286</td>\n",
       "      <td>0.958259</td>\n",
       "      <td>0.959167</td>\n",
       "      <td>0.000698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>17.334421</td>\n",
       "      <td>0.038112</td>\n",
       "      <td>4.978462</td>\n",
       "      <td>0.205645</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 100, 'gamma': 0.01}</td>\n",
       "      <td>0.742694</td>\n",
       "      <td>0.727143</td>\n",
       "      <td>0.732283</td>\n",
       "      <td>0.734048</td>\n",
       "      <td>0.006473</td>\n",
       "      <td>7</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.968831</td>\n",
       "      <td>0.057067</td>\n",
       "      <td>2.884583</td>\n",
       "      <td>0.018732</td>\n",
       "      <td>100</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 100, 'gamma': 0.001}</td>\n",
       "      <td>0.937277</td>\n",
       "      <td>0.912857</td>\n",
       "      <td>0.916965</td>\n",
       "      <td>0.922381</td>\n",
       "      <td>0.010683</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.083626</td>\n",
       "      <td>0.017297</td>\n",
       "      <td>2.265505</td>\n",
       "      <td>0.014762</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'C': 100, 'gamma': 0.0001}</td>\n",
       "      <td>0.920884</td>\n",
       "      <td>0.898571</td>\n",
       "      <td>0.908375</td>\n",
       "      <td>0.909286</td>\n",
       "      <td>0.009137</td>\n",
       "      <td>5</td>\n",
       "      <td>0.998212</td>\n",
       "      <td>0.997857</td>\n",
       "      <td>0.998930</td>\n",
       "      <td>0.998333</td>\n",
       "      <td>0.000446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time       ...         std_train_score\n",
       "0      17.034261       ...                0.000000\n",
       "1       5.775536       ...                0.001298\n",
       "2       8.492945       ...                0.001369\n",
       "3      17.427613       ...                0.000000\n",
       "4       5.040052       ...                0.000292\n",
       "5       3.963537       ...                0.000698\n",
       "6      17.334421       ...                0.000000\n",
       "7       4.968831       ...                0.000000\n",
       "8       3.083626       ...                0.000446\n",
       "\n",
       "[9 rows x 18 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# results\n",
    "cv_results = pd.DataFrame(clf.cv_results_)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# converting C to numeric type for plotting on x-axis\n",
    "cv_results['param_C'] = cv_results['param_C'].astype('int')\n",
    "\n",
    "# # plotting\n",
    "plt.figure(figsize=(16,6))\n",
    "\n",
    "# subplot 1/3\n",
    "plt.subplot(131)\n",
    "gamma_01 = cv_results[cv_results['param_gamma']==0.01]\n",
    "\n",
    "plt.plot(gamma_01[\"param_C\"], gamma_01[\"mean_test_score\"])\n",
    "plt.plot(gamma_01[\"param_C\"], gamma_01[\"mean_train_score\"])\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Gamma=0.01\")\n",
    "plt.ylim([0.60, 1])\n",
    "plt.legend(['test accuracy', 'train accuracy'], loc='lower right')\n",
    "plt.xscale('log')\n",
    "\n",
    "# subplot 2/3\n",
    "plt.subplot(132)\n",
    "gamma_001 = cv_results[cv_results['param_gamma']==0.001]\n",
    "\n",
    "plt.plot(gamma_001[\"param_C\"], gamma_001[\"mean_test_score\"])\n",
    "plt.plot(gamma_001[\"param_C\"], gamma_001[\"mean_train_score\"])\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Gamma=0.001\")\n",
    "plt.ylim([0.60, 1])\n",
    "plt.legend(['test accuracy', 'train accuracy'], loc='lower right')\n",
    "plt.xscale('log')\n",
    "\n",
    "\n",
    "# subplot 3/3\n",
    "plt.subplot(133)\n",
    "gamma_0001 = cv_results[cv_results['param_gamma']==0.0001]\n",
    "\n",
    "plt.plot(gamma_0001[\"param_C\"], gamma_0001[\"mean_test_score\"])\n",
    "plt.plot(gamma_0001[\"param_C\"], gamma_0001[\"mean_train_score\"])\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Gamma=0.0001\")\n",
    "plt.ylim([0.60, 1])\n",
    "plt.legend(['test accuracy', 'train accuracy'], loc='lower right')\n",
    "plt.xscale('log')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot above, we can observe that (from higher to lower gamma / left to right):\n",
    "- At very high gamma (0.01), the model is achieving 100% accuracy on the training data, though the test score is quite low (<75%). Thus, the model is overfitting.\n",
    "\n",
    "- At gamma=0.001, the training and test scores are comparable at around C=1, though the model starts to overfit at higher values of C\n",
    "\n",
    "- At gamma=0.0001, the model does not overfit till C=10 but starts showing signs at C=100. Also, the training and test scores are slightly lower than at gamma=0.001.\n",
    "\n",
    "Thus, it seems that the best combination is gamma=0.001 and C=1 (the plot in the middle), which gives the highest test accuracy (~92%) while avoiding overfitting.\n",
    "\n",
    "Let's now build the final model and see the performance on test data.\n",
    "\n",
    "### Final Model\n",
    "\n",
    "Let's now build the final model with chosen hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# optimal hyperparameters\n",
    "best_C = 1\n",
    "best_gamma = 0.001\n",
    "\n",
    "# model\n",
    "svm_final = svm.SVC(kernel='rbf', C=best_C, gamma=best_gamma)\n",
    "\n",
    "# fit\n",
    "svm_final.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "predictions = svm_final.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.924973544973545 \n",
      "\n",
      "[[3587    0   10   10    5   15   50   12   25    1]\n",
      " [   0 4108   14   16    5    3    6   18   10    5]\n",
      " [  24   23 3407   65   44    5   36  123   54    9]\n",
      " [   4   21   86 3502    5   89   11   73   76   33]\n",
      " [   3   11   36    7 3450   13   23   43    6  110]\n",
      " [  20   29   14  114   18 3020   79   53   36   35]\n",
      " [  31   12   11    1   14   34 3521   44   25    0]\n",
      " [   4   28   27    8   36    7    1 3739    7   97]\n",
      " [  14   59   32   80   22   97   25   44 3251   41]\n",
      " [  23   13   13   50   98    7    0  176   19 3379]]\n"
     ]
    }
   ],
   "source": [
    "# evaluation: CM \n",
    "confusion = metrics.confusion_matrix(y_true = y_test, y_pred = predictions)\n",
    "\n",
    "# measure accuracy\n",
    "test_accuracy = metrics.accuracy_score(y_true=y_test, y_pred=predictions)\n",
    "\n",
    "print(test_accuracy, \"\\n\")\n",
    "print(confusion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "The final accuracy on test data is approx. 92%. Note that this can be significantly increased by using the entire training data of 42,000 images (we have used just 10% of that!). \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
